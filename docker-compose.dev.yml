version: '3.8'

services:
  # Redis - 实时数据缓存
  redis:
    image: redis:7-alpine
    container_name: market_data_redis
    ports:
      - "6379:6379"
    volumes:
      - ./data/redis:/data
    command: redis-server --appendonly yes --maxmemory 512mb --maxmemory-policy allkeys-lru
    restart: unless-stopped
    healthcheck:
      test: ["CMD", "redis-cli", "ping"]
      interval: 10s
      timeout: 5s
      retries: 3

  # ClickHouse - 历史数据存储
  clickhouse:
    image: clickhouse/clickhouse-server:latest
    container_name: market_data_clickhouse
    ports:
      - "8123:8123"  # HTTP接口
      - "9000:9000"  # Native接口
    volumes:
      - ./data/clickhouse:/var/lib/clickhouse
      - ./config/clickhouse:/etc/clickhouse-server/config.d
      - ./logs/clickhouse:/var/log/clickhouse-server
    environment:
      CLICKHOUSE_DB: market_data
      CLICKHOUSE_USER: default
      CLICKHOUSE_PASSWORD: ""
      # 临时文件清理配置
      CLICKHOUSE_CONFIG_FILE: /etc/clickhouse-server/config.d/config.xml
    restart: unless-stopped
    healthcheck:
      test: ["CMD", "wget", "--no-verbose", "--tries=1", "--spider", "http://localhost:8123/ping"]
      interval: 10s
      timeout: 5s
      retries: 3
    # 资源限制
    deploy:
      resources:
        limits:
          memory: 4G
        reservations:
          memory: 1G

  # Zookeeper - Kafka依赖
  zookeeper:
    image: confluentinc/cp-zookeeper:7.4.0
    container_name: market_data_zookeeper
    environment:
      ZOOKEEPER_CLIENT_PORT: 2181
      ZOOKEEPER_TICK_TIME: 2000
    volumes:
      - ./data/zookeeper:/var/lib/zookeeper/data
    restart: unless-stopped

  # Kafka - 消息队列
  kafka:
    image: confluentinc/cp-kafka:7.4.0
    container_name: market_data_kafka
    depends_on:
      - zookeeper
    ports:
      - "9092:9092"
    environment:
      KAFKA_BROKER_ID: 1
      KAFKA_ZOOKEEPER_CONNECT: zookeeper:2181
      KAFKA_ADVERTISED_LISTENERS: PLAINTEXT://localhost:9092
      KAFKA_LISTENER_SECURITY_PROTOCOL_MAP: PLAINTEXT:PLAINTEXT
      KAFKA_INTER_BROKER_LISTENER_NAME: PLAINTEXT
      KAFKA_OFFSETS_TOPIC_REPLICATION_FACTOR: 1
      KAFKA_AUTO_CREATE_TOPICS_ENABLE: true
      KAFKA_NUM_PARTITIONS: 12
      KAFKA_DEFAULT_REPLICATION_FACTOR: 1
      # 开发环境优化配置
      KAFKA_LOG_RETENTION_HOURS: 24
      KAFKA_LOG_RETENTION_BYTES: 1073741824  # 1GB
      KAFKA_LOG_SEGMENT_BYTES: 104857600     # 100MB
      KAFKA_LOG_CLEANUP_POLICY: delete
    volumes:
      - ./data/kafka:/var/lib/kafka/data
    restart: unless-stopped
    healthcheck:
      test: ["CMD", "kafka-topics", "--bootstrap-server", "localhost:9092", "--list"]
      interval: 30s
      timeout: 10s
      retries: 3

  # Kafka UI - 开发调试工具
  kafka-ui:
    image: provectuslabs/kafka-ui:latest
    container_name: market_data_kafka_ui
    depends_on:
      - kafka
    ports:
      - "8080:8080"
    environment:
      KAFKA_CLUSTERS_0_NAME: local
      KAFKA_CLUSTERS_0_BOOTSTRAPSERVERS: kafka:9092
      KAFKA_CLUSTERS_0_ZOOKEEPER: zookeeper:2181
    restart: unless-stopped

  # Redis Commander - Redis管理工具
  redis-commander:
    image: rediscommander/redis-commander:latest
    container_name: market_data_redis_commander
    depends_on:
      - redis
    ports:
      - "8082:8081"
    environment:
      REDIS_HOSTS: local:redis:6379
    restart: unless-stopped

  # PostgreSQL - 用户数据和交易数据
  postgres:
    image: timescale/timescaledb:latest-pg14
    container_name: trading_postgres_23
    environment:
      POSTGRES_USER: postgres
      POSTGRES_PASSWORD: password
      POSTGRES_DB: trading_db
    ports:
      - "5432:5432"
    volumes:
      - ./data/postgres:/var/lib/postgresql/data
    restart: unless-stopped
    healthcheck:
      test: ["CMD-SHELL", "pg_isready -U postgres"]
      interval: 10s
      timeout: 5s
      retries: 3

networks:
  default:
    name: market_data_network
    driver: bridge

volumes:
  redis_data:
    driver: local
  clickhouse_data:
    driver: local
  kafka_data:
    driver: local
  zookeeper_data:
    driver: local